{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "# Introduction to Python - Lecture 09 (31Oct 2018)\n",
    "\n",
    "### Agenda for today:\n",
    "+ Introduction to Pandas\n",
    "+ Introduction to Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = np.array(\n",
    "      [[ 1,  1],\n",
    "       [ 4,  3],\n",
    "       [ 0,  1],\n",
    "       [-1,  1],\n",
    "       [ 0,  1],\n",
    "       [ 4, -2],\n",
    "       [-5,  1],\n",
    "       [-1,  0],\n",
    "       [-3,  3],\n",
    "       [ 3,  3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How do you return the first column? [1, 4, 0, -1, 0, 4, -5, -1, -3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How do you return the second column? [1, 3, 1, 1, 1, -2, 1, 0, 3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How do get the sum of each row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### How can we calculate the z score of each row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Setting a lower bound using numpy\n",
    "\n",
    "You can find all values that match a criteria us comparison operations\n",
    "\n",
    "**eg**\n",
    "```python\n",
    "lst = np.arange(0, 20)\n",
    "lst < 5\n",
    "```\n",
    "\n",
    "+ This will return an array with 20 elements, the first 5 will be True, the rest False.\n",
    "+ We can then use this as the index to the numpy array and set those values to something else\n",
    "```python\n",
    "lst = np.arange(0, 20)\n",
    "lst[lst < 5] = 0\n",
    "lst\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On removing noise from images\n",
    "\n",
    "The method you use to remove noise will vary depending on the type of noise you are trying to remove.\n",
    "\n",
    "Applying filters to the image is one method of trying to remove noise\n",
    "+ median filter\n",
    "+ gaussian filter\n",
    "+ dilation/erosion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Pandas\n",
    "\n",
    "Pandas is an external library like numpy and seaborn and needs to be installed using a package manager.\n",
    "\n",
    "Anaconda:\n",
    "+ conda install pandas\n",
    "Pip:\n",
    "+ pip install pandas\n",
    "\n",
    "**Note** Seaborn requires pandas as a dependancy, so you should already have it installed.\n",
    "\n",
    "When we would like to use pandas we need to import it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is a dataframe?\n",
    "\n",
    "A dataframe is a collection of data where each row consists of a collection of observations.\n",
    "\n",
    "#### Creating a dataframe\n",
    "\n",
    "There are many ways to create dataframes:\n",
    "+ Coverting a dictionary to a dataframe\n",
    "    ```python\n",
    "df = pd.Dataframe.from_dict( << dict >> )\n",
    "    ```\n",
    "+ Loading the data from a csv file\n",
    "    ```python\n",
    "df = pd.read_csv( << csv_path >> )\n",
    "    ```\n",
    "+ Load the data from a url\n",
    "    ```python\n",
    "url = \"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/trees.csv\"\n",
    "df = pd.read_csv(url)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data from a dictionary\n",
    "\n",
    "Some of these examples are taken from the pandas documentation (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.from_dict.html#pandas.DataFrame.from_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### By default, each item in the dictionary will represent a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'col_1': [3, 2, 1, 0], 'col_2': ['a', 'b', 'c', 'd']}\n",
    "pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### This can be changed by changing the orient parameter to 'index' (the default is 'column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'row_1': [3, 2, 1, 0], 'row_2': ['a', 'b', 'c', 'd']}\n",
    "pd.DataFrame.from_dict(data, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The names of the columns can be set using the columns parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(data, orient='index',\n",
    "                        columns=['A', 'B', 'C', 'D'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Alternatively you can specify the column names in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Tree1': {'girth': 8.3, 'height': 70, 'volume': 10.3},\n",
    "    'Tree2': {'girth': 8.6, 'height': 65, 'volume': 10.3},\n",
    "    'Tree3': {'girth': 8.8, 'height': 63, 'volume': 10.2}\n",
    "}\n",
    "pd.DataFrame.from_dict(data, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** Each row needs to have a unique identifier, in the above example this is represented by '**Tree#**'. Generally this is represented by an integer ranging from 0->n. \n",
    "+ In the above example we can reset the index to be the integers using the reset_index() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(data, orient='index').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Loading Data from a URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/trees.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing values in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Tree1': {'girth': 8.3, 'height': 70, 'volume': 10.3},\n",
    "    'Tree2': {'girth': 8.6, 'height': 65, 'volume': 10.3},\n",
    "    'Tree3': {'girth': 8.8, 'height': 63, 'volume': 10.2}\n",
    "}\n",
    "df = pd.DataFrame.from_dict(data, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columns\n",
    "\n",
    "+ To get a list of column names you can covert the dataframe into a list\n",
    "```python\n",
    "list(df)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Access columns using the column name in square brackets to return a series containing the data.\n",
    "```python\n",
    "df[\"column_name\"]\n",
    "```\n",
    "\n",
    "+ A series is a 1D array of id, value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"girth\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If instead of passing a single column name you pass a list of column names, a sub dataframe will be returned containing only those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"girth\", \"height\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rows\n",
    "\n",
    "Rows are accessed using either **loc** or **iloc**\n",
    "\n",
    "###### iloc\n",
    "+ This will access rows depending on their integer index\n",
    "+ The first row will have index 0\n",
    "+ Then next will have index 1, ...\n",
    "+ To extract the first row you would use the following command\n",
    "    + This will return a series containing the information from that row\n",
    "```python\n",
    "df.iloc[0]\n",
    "```\n",
    "+ To extract multiple rows you can pass a list of indices\n",
    "    + This will return a dataframe containing the specified rows\n",
    "```python\n",
    "df.iloc[[0, 1, 2]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[1, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### loc\n",
    "\n",
    "Various arguments will work with loc to extract rows from a dataframe\n",
    "\n",
    "+ A single index label\n",
    "    + Returns a series for that specific row\n",
    "    ```python\n",
    "df.loc[\"Tree2\"]\n",
    "    ```\n",
    "+ A list of index labels\n",
    "    + Returns a dataframe containing those rows\n",
    "    ```python\n",
    "df.loc[[\"Tree1\", \"Tree3\"]]\n",
    "    ```\n",
    "+ A boolean list\n",
    "    + Returns a dataframe for rows that are labeled true\n",
    "    ```python\n",
    "df.loc[[False, True]]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[False, True, False]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting data by value\n",
    "\n",
    "Comparison operators can be applied to series objects (which are numpy lists)\n",
    "For each value it will return either True or False depending on the comparison\n",
    "\n",
    "**eg**\n",
    "```console\n",
    "(1,1,1,5,5,5) > 3\n",
    "> [False, False, False, True, True, True]\n",
    "```\n",
    "\n",
    "This is convinient as **.loc** can use an array of booleans to extract rows.\n",
    "\n",
    "\n",
    "This allows for specific rows to be extracted from the dataframe depending on their value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Trees that are shorter than 70\n",
    "    + df[\"height\"] will return a series\n",
    "    + df[\"height\"] < 70 will return a list of booleans\n",
    "        + [False, True, True]\n",
    "    + We can then use this to extract those rows from the dataframe\n",
    "    ```python\n",
    "df.loc[df[\"height\"] < 70]\n",
    "    ```\n",
    "    \n",
    "##### How would you get the rows where the volume is equal to 10.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combining conditions\n",
    "\n",
    "Numpy has various bitwise operations which work on boolean arrays (bitwise operations work on binary sequences, a boolean list is a binary sequence)\n",
    "+ **&**\n",
    "    + This is and\n",
    "    + The resulting list will only be true where both conditions are true\n",
    "    ```python\n",
    "l1 = np.array([True, False])\n",
    "l2 = np.array([True, True])\n",
    "l1 & l2\n",
    "    ```\n",
    "+ |\n",
    "    + This is or\n",
    "    + The resulting list will be true where any of the conditions is true\n",
    "    ```python\n",
    "l1 = np.array([True, False])\n",
    "l2 = np.array([True, True])\n",
    "l1 | l2\n",
    "    ```\n",
    "+ ~\n",
    "    + This is negation\n",
    "    + The resulting True/False values will be flipped\n",
    "        ```python\n",
    "l1 = np.array([True, False])\n",
    "~l1\n",
    "    ```\n",
    "    \n",
    "**When comparing different conditions with pandas they should be put in parenthesis**\n",
    "```python\n",
    "df.loc[(df[\"something\"] > 5) & (df[\"nothing\"] != 4)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using this how can we extract all rows with height < 70 and volume equal to 10.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using this how can we extract all rows except with height < 70 and volume equal to 10.3?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading test datasets\n",
    "\n",
    "Seaborn has a few test datasets included with it\n",
    "\n",
    "+ Flights\n",
    "+ Iris\n",
    "+ many more (https://github.com/mwaskom/seaborn-data)\n",
    "\n",
    "These can be accessed using seaborns load_dataset function.\n",
    "This will return a pandas dataframe containing the data.\n",
    "\n",
    "```python\n",
    "df = sns.load_dataset(\"dataset_name\")\n",
    "```\n",
    "\n",
    "We will now load the **flights** dataset and perform some analysis on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df = sns.load_dataset(\"flights\")\n",
    "df.head() # This will return the first 5 rows of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting rows using strings\n",
    "\n",
    "Previously when we extracted rows it was using values, this will not work with strings.\n",
    "\n",
    "+ To extract string values we can use the **isin** function and a list of options\n",
    "+ Like other comparison operations this will return a list of boolean values\n",
    "+ This list can be used in conjunction with loc to access rows\n",
    "```python\n",
    "df[\"month\"].isin([\"January\"])\n",
    "df.loc[df[\"month\"].isin([\"January\"])]\n",
    "```\n",
    "+ As this is a list of booleans it can use the comparrisons we discussed earlier\n",
    "```python\n",
    "df.loc[(df[\"month\"].isin([\"January\"])) & (df[\"passengers\"] > 300)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby\n",
    "\n",
    "The groupby function of pandas allows you to gather statistics on certain groups within the data.\n",
    "\n",
    "\n",
    "On its own the groupby function will not actually do anything except create the groups. It needs to be combined with additional functions such as:\n",
    "+ mean()\n",
    "+ count()\n",
    "+ nunique()\n",
    "+ etc\n",
    "\n",
    "It is possible to iterate over the groups using for loops, but this is generally not required\n",
    "\n",
    "As an example we can group all of the flights by month and then sum all of the passengers for each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"month\") # This will not do anything except create the group objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"month\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"month\", \"passengers\"]].groupby(\"month\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"month\", \"passengers\"]].groupby(\"month\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"month\", \"passengers\"]].groupby(\"month\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How would we calculate which year had the most passengers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melting Data / Gathering data\n",
    "\n",
    "Data can be represented in two different forms:\n",
    "+ Long\n",
    "  + The flights data used previously would be an example of long data\n",
    "  + Each row only contains a single value (passengers)\n",
    "  + Long format is great for plotting data\n",
    "+ Wide\n",
    "  + Wide data contains multiple values per row\n",
    "  + For example using the flights data:\n",
    "    + each row could represent a year, each column a month\n",
    "  + This format is sometimes easier for performing calculations\n",
    "  + Often it is easier to store data in this format\n",
    "  \n",
    "Long data can be converted into wide data using the **pivot** function.\n",
    "\n",
    "Pivot can take three arguments:\n",
    "+ index\n",
    "  + which column should act as the index (remember index values should be unique)\n",
    "+ columns\n",
    "  + which column should be split into multiple columns\n",
    "+ values\n",
    "  + which column should act as the values \n",
    "\n",
    "To convert the flights dataset both year and month could act as the index and columns interchangeably.\n",
    "+ if index=\"year\"\n",
    "    + each year will be a row\n",
    "+ if index=\"month\"\n",
    "    + each month will be a row\n",
    "+ vice versa for the column\n",
    "\n",
    "The value will always be set to passengers\n",
    "\n",
    "```python\n",
    "df_wide = df.pivot(index='year', columns='month', values='passengers')\n",
    "df_wide\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = df.pivot(index='year', columns='month', values='passengers')\n",
    "df_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wide data can be converted into long data using the **melt** function.\n",
    "\n",
    "It has 5 arguments:\n",
    "+ id_vars\n",
    "  + columns which act as identifiers\n",
    "+ value_vars\n",
    "  + columns which contain the values\n",
    "  + if not specified it will use all columns except the id_var columns\n",
    "+ var_name\n",
    "  + name to use for the variable column\n",
    "+ value_name\n",
    "  + name to use for the value column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas remembers what changes were made to convert the long to wide\n",
    "# This resets the dataframe so that pandas does not know that the data was in long format\n",
    "df_wide = pd.DataFrame(df_wide.to_records())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide.melt(\n",
    "    id_vars=[\"year\"], \n",
    "#     value_vars=[\"January\", \"February\"], \n",
    "    var_name=\"months\", \n",
    "    value_name=\"passengers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Seaborn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets make this interactive\n",
    "\n",
    "Go [here](https://seaborn.pydata.org/api.html) and choose a type of plot, we will then discuss it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
